name: Run Scraper Every 30 Minutes

on:
  push:
    branches:
      - master
  schedule:
    - cron: "*/30 * * * *"
  workflow_dispatch:

jobs:
  run-scraper:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: |
        python -m venv .venv
        source .venv/bin/activate
        pip install --upgrade pip
        pip install -e .

    - name: Install Microsoft Edge
      run: |
        sudo apt update
        sudo apt install -y microsoft-edge-stable

    - name: Set execute permission on msedgedriver
      run: chmod +x ./src/visa_scraping/static/inputs/msedgedriver

    - name: Run scraper
      run: |
        source .venv/bin/activate
        python src/visa_scraping/ejecution.py
      env:
        USERNAME: ${{ secrets.SCRAPER_USERNAME }}
        PASSWORD: ${{ secrets.SCRAPER_PASSWORD }}

  upload-logs:
    runs-on: ubuntu-latest
    needs: run-scraper
    steps:
    - name: Create logs directory if it doesn't exist
      run: mkdir -p ./logs  # Asegurarse de que el directorio ./logs exista

    - name: Combine all logs
      run: |
        cat ./logs/logs.txt >> ./logs/all_logs.txt  # Combinar logs actuales con los anteriores

    - name: Upload consolidated logs as artifact
      uses: actions/upload-artifact@v3
      with:
        name: scraper-logs
        path: ./logs/all_logs.txt  # Subir el archivo consolidado de logs